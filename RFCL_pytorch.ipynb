{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFCL-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLPXKDwHv9NIVk24eULB5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckodser/RFCL/blob/main/RFCL_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M57qYUMcgLcn"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qElmfuksnKw0"
      },
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJWqKKyAnc6j",
        "outputId": "9627c411-e04a-4c20-ccad-6f1c2335cbaa"
      },
      "source": [
        "batch_size = 64\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2wlzg8YiLuc"
      },
      "source": [
        "reconnection_rate=500\n",
        "reduntant_node_ratio=0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie8kQg4nzqzF",
        "outputId": "64cadcda-347e-4fa4-9efd-3877375c6576"
      },
      "source": [
        "at=torch.Tensor([False,True,True,True])\n",
        "bt=torch.Tensor([1,2,3,4])\n",
        "print(at*bt)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 2., 3., 4.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h3N1jr7oTrp"
      },
      "source": [
        "class FewConnectionLinearFunction(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    # bias is an optional argument\n",
        "    def forward(ctx, input, weight, connections, bias=None):\n",
        "        \n",
        "        ctx.save_for_backward(input, weight, connections, bias)\n",
        "        output_feature=connections.shape[0]\n",
        "        output=torch.zeros([output_feature,input.shape[0]], dtype=torch.float32,device=device)\n",
        "        input=input.t()\n",
        "        for i in range(0,output_feature):\n",
        "            output[i]=torch.matmul(input[connections[i]].t(), weight[i])\n",
        "        if bias is not None:\n",
        "            output += bias.unsqueeze(1).expand_as(output)\n",
        "        return output.t()\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def find_reduntant_connections(weight):\n",
        "        #there is a problem in this part\n",
        "        #each node makes a useless edge which this part keep choosing. \n",
        "        #that node count on the other edge for computing its output and  \n",
        "        #when it should introduce a reduntant edge it will intruduce the\n",
        "        #same edge each time.\n",
        "\n",
        "        weight_2=torch.square(weight)\n",
        "        minn=torch.min(weight_2,1)\n",
        "        y=torch.div(minn.values,torch.mean(weight_2,1))\n",
        "        y=(torch.kthvalue(y,int(reduntant_node_ratio*weight.shape[0])).values>y)\n",
        "        print(\"removed connections:\"+str(torch.sum(y))+\"   ration of removed connections:\"+str(torch.sum(y)/weight.shape[0]))\n",
        "        print((y*minn.indices)[0:min(20,y.shape[0])])\n",
        "        return y,minn.indices\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def find_best_match(input,grad_output_t,is_remove,connections): \n",
        "      # this part didn't check and debug\n",
        "      # this part should improve its performance \n",
        "      points_num=input.shape[1]\n",
        "      lines_num=grad_output_t.shape[0]\n",
        "      best_match=torch.zeros_like(is_remove)\n",
        "      for i in range(lines_num):\n",
        "          if is_remove[i]:\n",
        "            line=grad_output_t[i].t()/torch.sqrt(torch.sum(torch.square(grad_output_t[i])))\n",
        "            dist=torch.sum(torch.square(torch.matmul(torch.matmul(line,input).t(),line).t()-input),0)\n",
        "            dist[connections[i]]+=10000\n",
        "            best_match[i]=torch.argmin(dist)\n",
        "      return best_match\n",
        "                \n",
        "\n",
        "    @staticmethod\n",
        "    def layer_reconnection(ctx, grad_output_t):\n",
        "        if torch.rand(1)<1-(1/reconnection_rate):  #for each reconnection_rate mini batch preform layer_reconnection\n",
        "            return \n",
        "        input, weight, connections, bias = ctx.saved_tensors\n",
        "        output_feature=connections.shape[0]\n",
        "        input_feature=input.shape[1]\n",
        "        is_remove, which_remove=FewConnectionLinearFunction.find_reduntant_connections(weight)\n",
        "        best_match = FewConnectionLinearFunction.find_best_match(input,grad_output_t,is_remove,connections)\n",
        "        for i in range(output_feature):\n",
        "            if is_remove[i]:\n",
        "              weight[i][which_remove[i]]=0\n",
        "              connections[i][which_remove[i]]=best_match[i]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_output_t=torch.unsqueeze(grad_output.t(),2)\n",
        "        input, weight, connections, bias = ctx.saved_tensors\n",
        "        input_t=input.t()\n",
        "        grad_input=torch.zeros_like(input_t)\n",
        "        grad_weight=torch.zeros_like(weight)\n",
        "        weight_u=torch.unsqueeze(weight,1)\n",
        "        grad_bias=torch.zeros_like(bias)\n",
        "        output_feature=connections.shape[0]\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            for i in range(0,output_feature):\n",
        "                grad_input[connections[i]]+= torch.matmul(grad_output_t[i],weight_u[i]).t()  \n",
        "        \n",
        "        if ctx.needs_input_grad[1]:\n",
        "            for i in range(0,output_feature):\n",
        "                grad_weight[i]+= torch.squeeze(torch.matmul(input_t[connections[i]],grad_output_t[i]).t(),0)   \n",
        "        \n",
        "        if bias is not None and ctx.needs_input_grad[3]:\n",
        "            grad_bias = grad_output.sum(0)\n",
        "        \n",
        "        FewConnectionLinearFunction.layer_reconnection(ctx, grad_output_t)\n",
        "\n",
        "        return grad_input.t(), grad_weight, None , grad_bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQnvky4O_bD"
      },
      "source": [
        "class FewConnectionLinear(nn.Module):\n",
        "    def __init__(self, input_features, output_features, connection_num,bias=True):\n",
        "        super(FewConnectionLinear, self).__init__()\n",
        "        self.input_features = input_features\n",
        "        self.output_features = output_features\n",
        "\n",
        "        self.connection_num=connection_num\n",
        "\n",
        "        self.weight = nn.Parameter(torch.empty(output_features, connection_num))\n",
        "        self.connections = nn.Parameter(torch.empty(output_features, connection_num), requires_grad=False)\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.empty(output_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        \n",
        "        #  initialize weights\n",
        "        \n",
        "        self.weight.data.normal_(mean=0.0, std=np.sqrt(1/self.connection_num))\n",
        "        if self.bias is not None:\n",
        "            torch.nn.init.zeros_(self.bias)#uniform -0.0001 +0.0001 work very well to\n",
        "      \n",
        "        self.connections.data=torch.from_numpy(self.connection_initializer())\n",
        "\n",
        "    def connection_initializer(self):\n",
        "      # this part need improvement\n",
        "      x=11 #x=(self.input_features)//(self.output_features)\n",
        "\n",
        "      aa=np.arange(self.connection_num)\n",
        "      bb=np.arange(self.output_features)*x\n",
        "      bb=bb.reshape((self.output_features,1))\n",
        "      cc=np.ones_like(aa).reshape((1,self.connection_num))\n",
        "\n",
        "      return np.remainder(aa+np.matmul(bb,cc),self.input_features)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # See the autograd section for explanation of what happens here.\n",
        "        return FewConnectionLinearFunction.apply(input, self.weight, self.connections,self.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBXDBVm6n7jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e3d36b-4492-451b-9ae4-98ba3f23bdef"
      },
      "source": [
        "# Get cpu or gpu device for training.1\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            FewConnectionLinear(28*28, 512,50),\n",
        "            nn.BatchNorm1d(512,affine=False),nn.ReLU(),\n",
        "            FewConnectionLinear(512, 512,10),\n",
        "            nn.BatchNorm1d(512,affine=False),nn.ReLU(),\n",
        "            FewConnectionLinear(512, 512,10),\n",
        "            nn.BatchNorm1d(512,affine=False),nn.ReLU(),\n",
        "            FewConnectionLinear(512, 512,10),\n",
        "            nn.BatchNorm1d(512,affine=False),nn.ReLU(),\n",
        "            FewConnectionLinear(512, 10,50),\n",
        "            nn.Softmax(),      \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x=self.linear_relu_stack(x)\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): FewConnectionLinear()\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): FewConnectionLinear()\n",
            "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): FewConnectionLinear()\n",
            "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): FewConnectionLinear()\n",
            "    (10): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): FewConnectionLinear()\n",
            "    (13): Softmax(dim=None)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-zC9WMAoGty"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY3g_kuDoMJw"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       # return\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(batch)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIflNLQDoTTJ"
      },
      "source": [
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "           # return #for testing pytorch\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y8B56WGwoTia",
        "outputId": "cc3eb195-d409-45fd-dafa-7561882ab8a1"
      },
      "source": [
        "epochs = 10\n",
        "for name,param in model.named_parameters():\n",
        "  if name==\"linear_relu_stack.0.connections\":\n",
        "    print(param.data)\n",
        "  print(name)\n",
        "\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "\n",
        "for name,param in model.named_parameters():\n",
        "  if name==\"linear_relu_stack.0.connections\":\n",
        "    print(param.data)\n",
        "  print(name)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear_relu_stack.0.weight\n",
            "tensor([[  0,   1,   2,  ...,  47,  48,  49],\n",
            "        [ 11,  12,  13,  ...,  58,  59,  60],\n",
            "        [ 22,  23,  24,  ...,  69,  70,  71],\n",
            "        ...,\n",
            "        [111, 112, 113,  ..., 158, 159, 160],\n",
            "        [122, 123, 124,  ..., 169, 170, 171],\n",
            "        [133, 134, 135,  ..., 180, 181, 182]])\n",
            "linear_relu_stack.0.connections\n",
            "linear_relu_stack.0.bias\n",
            "linear_relu_stack.3.weight\n",
            "linear_relu_stack.3.connections\n",
            "linear_relu_stack.3.bias\n",
            "linear_relu_stack.6.weight\n",
            "linear_relu_stack.6.connections\n",
            "linear_relu_stack.6.bias\n",
            "linear_relu_stack.9.weight\n",
            "linear_relu_stack.9.connections\n",
            "linear_relu_stack.9.bias\n",
            "linear_relu_stack.12.weight\n",
            "linear_relu_stack.12.connections\n",
            "linear_relu_stack.12.bias\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "0\n",
            "loss: 2.316355  [    0/60000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 0, 0, 4, 5, 6, 0, 3, 0, 0, 0, 0, 0, 0, 9, 0, 8, 0, 9, 0])\n",
            "100\n",
            "loss: 2.164378  [ 6400/60000]\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 0, 0, 7, 5, 6, 0, 3, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 9, 0])\n",
            "200\n",
            "loss: 1.951322  [12800/60000]\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 0, 0, 0, 5, 0, 0, 3, 0, 5, 0, 0, 0, 0, 9, 0, 0, 0, 9, 0])\n",
            "300\n",
            "loss: 1.911749  [19200/60000]\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([2, 1, 0, 4, 0, 8, 7, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 9, 0])\n",
            "400\n",
            "loss: 1.818340  [25600/60000]\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 0, 0, 0, 5, 0, 0, 3, 0, 5, 0, 0, 0, 0, 9, 0, 0, 5, 9, 0])\n",
            "500\n",
            "loss: 1.753925  [32000/60000]\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 3, 0, 5, 0])\n",
            "removed connections:tensor(152)   ration of removed connections:tensor(0.2969)\n",
            "tensor([0, 0, 0, 0, 5, 0, 0, 3, 0, 5, 0, 0, 0, 0, 9, 0, 0, 5, 9, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-330-8734e717878c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-328-a3e73212f273>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m        \u001b[0;31m# return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-324-a24dfc367911>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mgrad_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cjod8CioTyF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2KhbmMYoT3W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7puG0HaoT8H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHSk224doUAH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddW-p9ioUDg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "UAqKKUzyZJny",
        "outputId": "a72307a5-1c7f-418a-f69a-cad26f68d374"
      },
      "source": [
        "test_num=70\n",
        "input_features=50\n",
        "output_features=20\n",
        "connection_num=10\n",
        "input=(torch.randn(test_num,28,28,dtype=torch.float32,requires_grad=True))\n",
        "test = torch.autograd.gradcheck(model, input, eps=1e-6, atol=1e-4)\n",
        "print(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py:380: UserWarning: Input #0 requires gradient and is not a double precision floating point or complex. This check will likely fail if all the inputs are not of double precision floating point or complex. \n",
            "  f'Input #{idx} requires gradient and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-3f78905b91cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconnection_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad)\u001b[0m\n\u001b[1;32m    421\u001b[0m         analytical, reentrant, correct_grad_sizes, correct_grad_types = get_analytical_jacobian(tupled_inputs,\n\u001b[1;32m    422\u001b[0m                                                                                                 \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                                                                                                 nondet_tol=nondet_tol)\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mnumerical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_numerical_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupled_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/gradcheck.py\u001b[0m in \u001b[0;36mget_analytical_jacobian\u001b[0;34m(input, output, nondet_tol, grad_out)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjacobian_c\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacobian_reentrant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             grads_input = torch.autograd.grad(output, diff_input_list, grad_output,\n\u001b[0;32m--> 186\u001b[0;31m                                               retain_graph=True, allow_unused=True)\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mjacobian_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjacobian_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_input_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0md_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-d7204f24ab9e>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;31m#print(torch.unsqueeze(grad_output[:,i],1).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                \u001b[0;31m# print(torch.unsqueeze(weight[i].t(),0).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mgrad_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconnections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#  input.t()[connections[i]].t()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCIRP5iQoUG3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}